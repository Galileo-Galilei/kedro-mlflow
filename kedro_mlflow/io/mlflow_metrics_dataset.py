import csv
import json
import os
from pathlib import Path, PurePosixPath
from typing import Any, Dict, List, Optional, Union

import mlflow
from cachetools import Cache
from kedro.io import AbstractVersionedDataSet
from kedro.io.core import DataSetError, Version


class MlflowMetricsDataSet(AbstractVersionedDataSet):
    """This class represent mlflow metrics.

    It decorates their ``save`` method to log the metrics in mlflow when
    ``save`` is called.
    """

    DEFAULT_JSON_SAVE_ARGS: Dict[str, Any] = {"indent": 2}
    SUPPORTED_FORMATS: List[str] = ["json", "csv"]

    def __init__(
        self,
        prefix: Optional[str] = None,
        filepath: Optional[Union[str, PurePosixPath]] = None,
        version: Optional[Version] = None,
        format: str = "json",
    ):
        """Initialise MLflowMetricsDataSet.

        Args:
            prefix (Optional[str]): Prefix for metrics logged in mlflow.
            filepath (Optional[Union[str, Path]]): Path to file where dataset
                with metrics will be saved. If not set metrics will be logged
                in mlflow and will not be saved on disk.
            version (Optional[Version]): If specified, should be an instance of
                ``kedro.io.core.Version``. If its ``load`` attribute is
                None, the latest version will be loaded. If its ``save``
                attribute is None, save version will be autogenerated.
            format (str): Format of saved metrics dataset. Possible choices:
                ``json`` and ``csv``.
        """
        if format not in self.SUPPORTED_FORMATS:
            raise ValueError(
                f"Given format {format} is not supported. "
                f"Available choices are {', '.join(self.SUPPORTED_FORMATS)}."
            )
        self._output_format = format
        self._filepath = PurePosixPath(filepath) if filepath else filepath
        self._prefix = prefix
        self._version = version

        # 1 entry for load version, 1 for save version
        self._version_cache = Cache(maxsize=2)

    def _load_json(self) -> Dict[str, Union[float, List[float]]]:
        """Load MlflowMetricDataSet from json file.

        Returns:
            Dict[str, Union[int, float]]: Dictionary with MLflow metrics.
        """
        with open(self._get_load_path(), "r") as f:
            return json.load(f)

    def _load_csv(self) -> Dict[str, Union[float, List[float]]]:
        """Load MlflowMetricDataSet from csv file.

        Returns:
            Dict[str, Union[int, float]]: Dictionary with MLflow metrics.
        """
        with open(self._get_load_path(), "r") as f:
            reader = csv.DictReader(f)
            for row in reader:
                for key, value in row.items():
                    try:
                        row[key] = float(value)
                    except ValueError:
                        # This is the simplest and safest way to parse
                        # string with list of floats.
                        value = json.loads(value)
                        if not all([isinstance(x, float) for x in value]):
                            raise ValueError("Given file is invalid metrics dataset.")
                        row[key] = value
                # CSV file with metrics will always have just one row.
                # If there are other rows we simple ignore it.
                return dict(row)  # In python 2.6 returned rows are of type OrderedDict

    def _load(self) -> Dict[str, Union[float, List[float]]]:
        """Load MlflowMetricDataSet.

        Returns:
            Dict[str, Union[int, float]]: Dictionary with MLflow metrics.
        """
        if self._filepath:
            load = getattr(self, f"_load_{self._output_format}")
            return load()
        raise FileNotFoundError(
            "Filepath parameter is not specified, cannot load dataset."
        )

    def _save_json(self, data: Dict[str, Union[float, List[float]]]) -> None:
        """Save given metrics dataset as json file.

        Args:
            data (data: Dict[str, float]): MLflow metrics data.
        """
        filepath = self._get_save_path()
        os.makedirs(filepath.parent, exist_ok=True)
        with open(filepath, "w") as f:
            json.dump(data, f, **self.DEFAULT_JSON_SAVE_ARGS)

    def _save_csv(self, data: Dict[str, Union[float, List[float]]]) -> None:
        """Save given metrics dataset as csv file.

        Args:
            data (data: Dict[str, float]): MLflow metrics data.
        """
        filepath = self._get_save_path()
        os.makedirs(filepath.parent, exist_ok=True)
        with open(filepath, "w") as f:
            writer = csv.DictWriter(f, fieldnames=data.keys())
            writer.writeheader()
            writer.writerow(data)

    def _save(self, data: Dict[str, Union[float, List[float]]]) -> None:
        """Save given dataset and log it in mlflow as metrics.

        Args:
            data (data: Dict[str, float]): MLflow metrics data.
        """
        for key, value in data.items():
            if self._prefix:
                key = f"{self._prefix}.{key}"
            if isinstance(value, list):
                for x in value:
                    mlflow.log_metric(key, x)
            else:
                mlflow.log_metric(key, value)

        if self._filepath:
            save = getattr(self, f"_save_{self._output_format}")
            save(data)

    def _exists(self) -> bool:
        """Check if dataset exists.
        """
        try:
            load_path = self._get_load_path()
        except DataSetError:
            return False
        return Path(load_path).exists()

    def _describe(self) -> Dict[str, Any]:
        """Describe dataset.

        Returns:
            Dict[str, Any]: Dictionary with dataset description.
        """
        return {
            "filepath": self._filepath,
            "version": self._version,
            "prefix": self._prefix,
            "format": self._output_format,
        }
